defaults:
  - override hydra/job_logging: colorlog
  - override hydra/hydra_logging: colorlog

max_steps: 10
num_episodes: 3
seed: 0
gamma: 0.98
save_log: false
replay_path: None

env_name: &env_name "MiniGrid-Empty-5x5-v0"

actions: &actions [0, 1, 2, 3, 4, 5]
env:
  _target_: uncertain_worms.environments.minigrid.minigrid_env.MinigridEnvironment
  fully_obs: false
  env_name: ${env_name}

agent:
  _target_: uncertain_worms.policies.partially_obs_planning_agent.LLMPartiallyObsPlanningAgent
  fully_obs: false
  env_code_path: environments/minigrid
  actions: *actions
  learn_transition: true
  learn_reward: true
  dataset_path: "environments/minigrid/trajectory_data/${env_name}.pkl"
  max_attempts: 250000
  num_particles: 100
  empty_state:
    _target_: uncertain_worms.environments.minigrid.minigrid_env.minigrid_empty_state_gen
    env_name: ${env_name}

  empty_observation:
    _target_: uncertain_worms.environments.minigrid.minigrid_env.minigrid_empty_observation_gen
    
  planner:
    _target_: uncertain_worms.planners.PO_DAStar.PO_DAStar
    actions: *actions

    empty_observation:
      _target_: uncertain_worms.environments.minigrid.minigrid_env.minigrid_empty_observation_gen
      
    initial_model: 
      _target_: uncertain_worms.environments.minigrid.minigrid_env.minigrid_hardcoded_initial_model_gen
      env_name: ${env_name}
    transition_model: 
      _target_: uncertain_worms.structs.empty_transition_model_gen
    reward_model:
      _target_: uncertain_worms.structs.empty_reward_model_gen
    observation_model:
      _target_: uncertain_worms.environments.minigrid.minigrid_env.minigrid_hardcoded_observation_model_gen